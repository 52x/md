---
title: A/B Testing 统计学原理简述
date: 2016-12-13 10:32:15
tags: [Math, BI]
---

考虑一个常见的场景：为提高某个页面的转化率，PM 提出新的方案，想通过试验决定是否改版。为此，将用户分为 A/B 两组做试验：A 组使用原方案，试验样本的转化率为5%；B 组使用新的测试方案，转化率5.2%。那么，我们能说新方案更好吗？样本提高的0.2%，也许不算明显，会不会是随机误差导致的？

本文介绍如何利用假设检验，建立对此类问题的判断流程。*以下重点说明原理，如需计算细节，请参考文中链接。*

## 假设检验

统计学中，判断的命题称为`假设`，一个判断的两个对立的结果分别对应`原假设`和`备择假设`。做判断的过程称为`假设检验`。

对本文开头的设定，可以选取原假设：新方案转化率 ≤ 原方案；备择假设：新方案转化率 > 原方案。

一个简单的判断标准：当 `B 组样本转化率 - A 组样本转化率` 差值较大，`拒绝原假设`，认为新方案确实优于原方案；而当差值较小，`不拒绝原假设`，即认为 A/B 方案接近。简单来说，假设检验就是对这样的判断标准进行错误概率的量化。

> 可能的问题：原假设、备择假设是否可以交换？例如选取原假设为：新方案转化率 > 原方案？原则上可以；之所以按上文中选择，是出于一种常用的错误控制方法，原理见下文的 I/II 类错误部分。

以上的判断标准中，我们用 `B 组样本转化率 - A 组样本转化率` 作为判断依据，这个依据称为`检验统计量`；对不同类型的检验问题，采用不同的检验统计量。而差异的『较大或较小』需要以某个阈值为依据，当检验统计量的值超过这个阈值时，称为落入`拒绝域`，我们就做出`拒绝原假设`的判断。

<!-- more -->

## I/II 类错误，功效函数

### 任何判断都可能出错

采用任何拒绝域，我们都面临判断错误的可能：

1. 错误地拒绝了原假设。例如当 B 组样本转化率为5.6%，此时检验统计量为0.6%，落入拒绝域；但当 A/B 组内样本量较小，或各自很不稳定，0.6%的差异也可能是随机波动导致的，这时也许`原假设为真`，但我们拒绝了它
2. 错误地接受了原假设。例如当 B 自样本转化率为5.4%，此时检验统计量为0.4%，未落入拒绝域。但当 A/B 各自很稳定，且在大量的样本下，差异仍然保持0.4%，也许新方案确实更好，但我们接受了原假设

以上两类错误，分别称为 `I 类错误`、`II 类错误`。在这里，如果增大拒绝域中采用的阈值，I 类错误的概率会减小，II 类错误的概率会增大；当减小阈值，变化方向相反。因此：**无法同时降低 I/II 类错误的发生概率。**

### 设定显著水平，控制 I 类错误

既然两类错误的概率无法同时减低，就优先控制成本较高的错误。实际业务中，**成本较高**往往有对应场景。仍以转化率为例，通常的出发点是： 除非新方案有明显改进，否则不会冒着改变用户习惯的风险，弃用原方案。因此，错误地认为新方案有明显改进，比错误地认为新方案没有改进成本更高。

习惯上，选取错误成本较高的判断作为原假设，并优先控制 I 类错误的发生概率。于是，就有了本文第一部分的设定方式。

习惯上 (again)，我们以1%、5%或10%作为 I 类错误的上限。按照这些上限确定拒绝域，I 类错误的发生概率就得到了控制。这些上限称为假设检验的`显著性水平`。具体选择怎样的显著性水平，取决于对 I 类错误的容忍度；不过，实践中往往*视心情而定……*

> 可能的问题：I 类错误的上限，是能随意控制的吗？是的，例如在本文的案例中，为了降低 I 类错误的概率，只需要增大阈值。例如拒绝域设为 (50%, +∞)，就是说只有当 B 组样本的转化率 ≥ 55% 时，才拒绝原假设，可想而知，这种判断标准极大减小了 I 类错误的可能性；但与此同时，差异 < 50% 的情况下 II 类错误的可能增加了。
>
> 关于拒绝域的计算，自然界有个神奇的规律：[中心极限定理](https://en.wikipedia.org/wiki/Central_limit_theorem)。简单来说，就是不论样本的自身特征，只要满足一定的样本量，均值就近似属于某个[特定的分布](https://en.wikipedia.org/wiki/Normal_distribution)家族。在这个分布下，指定显著性水平，就能得到拒绝域。详情参见[这里](https://en.wikipedia.org/wiki/Statistical_hypothesis_testing)。

综上，只要选取适当的拒绝域，就能控制 I 类错误，那么 II 类错误呢？

### 利用功效函数，控制 II 类错误

`功效函数`：在检验参数为任意值的情况下，检验统计量落入拒绝域的概率。对应本文中的问题，参数是指新方案与原方案的转化率的差，而检验统计量是 B 组样本转化率 - A 组样本转化率；也可以说：检验统计量是参数在有限样本中的体现。

根据功效函数的定义：当原假设成立时，功效函数的值是 I 类错误概率；当备择假设成立时，功效函数的值是 (1 - II 类错误的概率)。显然，我们希望：参数满足原假设时，功效函数尽可能小；参数满足备择假设时，功效函数尽可能大。

功效函数的作用，可以理解为评估假设检验是否『合格』。评估方法：选取一个我们认为**业务上刚好足够有意义的差异**，看检验能够以较高的概率检测到它，即功效函数在这个差异下的值是否足够大，即 II 类错误的概率是否足够小。

例如：我们认为，当实际转化率的提高 ≥1% 时，对业务是有足够意义的，因此我们要求：对1%的转化率之差，必须以 ≥ 80% 的概率拒绝原假设。如果功效函数的值不够大，则检验过程不合格；需要提升样本量，重新评估。

> 可能的问题：提升样本量，就能让检验更有效吗？设样本量为 m，根据中心极限定理，参数分布的方差与 √m 成反比。随着样本量的提高，参数取值会更『集中』，从而使发生相同差异的概率更小。理论上，只要无限提高样本量，检验就会变得无限敏感。但实际情况是：样本总是有限的；在提高样本量后，差异可能会变小。
>
> 既然可以通过`样本量`、`功效函数`、`参数差异下限`、`II 类错误的概率上限`来评估检验是否合格，当然也可以通过后3项确定合格检验的样本量。事实上，这正是功效函数的通常用法，即确定合格检验所需的最低样本量。

综上，控制 II 类错误的方法是，保障成功检测某个差异的概率，以此决定检验所需的最低样本量。如果样本无法满足，则不能通过假设检验得到有效结论。

## 显著性 ≠ 全部

选定显著性水平，样本量也满足，是不是就能完全信任假设检验的结果呢？从统计学角度，是；从业务需要的角度，未必。

介绍功效函数的时候，我们提到：可以通过提升样本量，让检验变得无限敏感。当样本量较大，检验倾向于使更小的差异落入拒绝域。所以，由本文开头的 B 组样本5.2%的转化率，也许会得到新方案优于原方案的结论；但从业务需要考虑，一个有一定错误概率的、且仅有0.2%的提升，是否满足我们对一个改进的预期？是否值得让所有用户去适应新方案？恐怕要谨慎权衡。

> 大样本带来的敏感度问题，也有常用的『解决』方案，例如：放宽检验的显著性水平；对假设问题添加偏移量，如『新方案转化率 ≤ 原方案 + 0.2%』。大样本是互联网行业的常态，有时，为了更全面看待 A/B 效果，可以把试验结果当做[参数估计](https://en.wikipedia.org/wiki/Estimation_theory)和[置信区间](https://en.wikipedia.org/wiki/Confidence_interval)问题分析，而不只是假设检验。

## 小结

### 流程

总结假设检验的流程如下

![](http://ohaltm7p2.bkt.clouddn.com/image/hexo/ab-testing-methodology-flowchart.png)

### 案例

以本文开头的转化率假设检验为例，R 分析流程如下。

```R
# 载入 pwr 包用于功效函数计算
require(pwr)

# 设定显著性水平, 约束 I 类错误
significance_level <- 0.05

# 假设我们认为新方案转化率的提高 ≥ 1% 时, 对业务有意义显著, 希望以 80% 的概率检测到差异, 控制 II 类错误
# 以等样本检验为例, 确定所需的最低样本量
# 结果说明: 每组的样本量需最低为 6413
pwr.2p.test(h = ES.h(0.05,0.06), 
            sig.level = significance_level, power = 0.8, alternative = "less")
----
     Difference of proportion power calculation for binomial distribution (arcsine transformation) 

              h = -0.04390731
              n = 6413.933
      sig.level = 0.05
          power = 0.8
    alternative = less

NOTE: same sample sizes

# 假设我们的样本量满足条件, 以下进行检验
# 场景一
# 试验样本: 两组样本的样本量分别为 24000, A/B 组的转化人数分别为 1200, 1450
# 参数说明: 按照本文开始的设定, 备择假设的形式为 "less"; 置信度 = 1 - 显著性水平 = 0.95
# 结果说明: p值在显著性水平范围内, 拒绝原假设; 同时 B 组样本提升超过 1%, 业务上有意义, 认为新方案有提升
stats::prop.test(x = c(1200,1450), n = c(24000, 24000), conf.level = 1 - significance_level,alternative = "less")
----
       	2-sample test for equality of proportions with continuity correction

data:  c(1200, 1450) out of c(24000, 24000)
X-squared = 24.764, df = 1, p-value = 3.24e-07
alternative hypothesis: less
95 percent confidence interval:
 -1.00000000 -0.00694658
sample estimates:
    prop 1     prop 2 
0.05000000 0.06041667
# 场景二
# 试验样本: 两组样本的样本量分别为 24000, A/B 组的转化人数分别为 1200, 1230
# 参数说明: 按照本文开始的设定, 备择假设的形式为 "less"; 置信度 = 1 - 显著性水平 = 0.95
# 结果说明: p值超过显著性水平范围, 不拒绝原假设; 认为新方案无提升
stats::prop.test(x = c(1200,1230), n = c(24000, 24000), conf.level = 1 - significance_level,alternative = "less")
----
          	2-sample test for equality of proportions with continuity correction

data:  c(1200, 1230) out of c(24000, 24000)
X-squared = 0.36455, df = 1, p-value = 0.273
alternative hypothesis: less
95 percent confidence interval:
 -1.000000000  0.002083488
sample estimates:
 prop 1  prop 2 
0.05000 0.05125 
```



## 参考

- Probability and Statistics (4th Edition) by Morris H. DeGroot
